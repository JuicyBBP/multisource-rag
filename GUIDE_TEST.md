# Guide de Test - MultiSource RAG System

## üìã Pr√©requis

Assurez-vous que :
- ‚úÖ L'environnement virtuel est activ√©
- ‚úÖ Toutes les d√©pendances sont install√©es
- ‚úÖ Le fichier `.env` contient votre cl√© API Mistral (ou OpenAI/Anthropic)

## üöÄ M√©thode 1 : Test Complet avec Interface Web (Recommand√©)

### √âtape 1 : Lancer l'API Backend

Ouvrez un premier terminal et ex√©cutez :

```bash
./start_api.sh
```

Vous devriez voir :
```
üöÄ Starting FastAPI server...
API will be available at: http://localhost:8000
```

Attendez que le message apparaisse :
```
INFO: Application startup complete.
INFO: Uvicorn running on http://0.0.0.0:8000
```

### √âtape 2 : Lancer le Frontend Streamlit

Ouvrez un **deuxi√®me terminal** et ex√©cutez :

```bash
./start_frontend.sh
```

Vous devriez voir :
```
üé® Starting Streamlit frontend...
Frontend will be available at: http://localhost:8501
```

Le navigateur devrait s'ouvrir automatiquement √† `http://localhost:8501`

### √âtape 3 : Tester l'Upload de Documents

1. Dans l'interface Streamlit, allez sur **üì§ Upload Documents**
2. Cliquez sur **Browse files**
3. S√©lectionnez un document de test (PDF, DOCX, TXT ou MD)
4. Cliquez sur **üöÄ Upload and Process**
5. Attendez que le traitement se termine (quelques secondes)

Vous devriez voir : `‚úÖ votre_document.ext: X chunks created`

### √âtape 4 : Tester les Questions/R√©ponses

1. Allez sur **üí¨ Ask Questions**
2. Posez une question dans le chat, par exemple :
   - "Quels sont les trois types de machine learning ?"
   - "Qu'est-ce que le deep learning ?"
   - "Quelles sont les applications du machine learning ?"

3. Observez :
   - La r√©ponse g√©n√©r√©e par l'IA
   - Les sources utilis√©es (avec score de similarit√©)
   - Le contexte extrait de vos documents

### √âtape 5 : Consulter les Statistiques

1. Allez sur **üìä Statistics**
2. V√©rifiez :
   - Nombre de chunks stock√©s
   - Nombre de documents
   - Configuration du mod√®le d'embeddings
   - Param√®tres du LLM

---

## üîß M√©thode 2 : Test via l'API Directement

### Test 1 : Health Check

```bash
curl http://localhost:8000/api/v1/health
```

R√©ponse attendue :
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "components": {...}
}
```

### Test 2 : Upload d'un Document

```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@votre_document.txt"
```

### Test 3 : Poser une Question

```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quels sont les types de machine learning ?",
    "n_results": 5,
    "min_similarity": 0.7,
    "include_sources": true
  }'
```

### Test 4 : Obtenir les Statistiques

```bash
curl http://localhost:8000/api/v1/stats
```

---

## üß™ M√©thode 3 : Test avec Script Python

Cr√©ez un fichier `test_api.py` :

```python
import requests
import json

API_URL = "http://localhost:8000/api/v1"

# 1. Test health
print("1. Testing health endpoint...")
response = requests.get(f"{API_URL}/health")
print(f"Status: {response.status_code}")
print(f"Response: {response.json()}\n")

# 2. Upload document
print("2. Uploading document...")
with open("votre_document.txt", "rb") as f:
    files = {"file": ("votre_document.txt", f, "text/plain")}
    response = requests.post(f"{API_URL}/ingest", files=files)
print(f"Status: {response.status_code}")
print(f"Response: {json.dumps(response.json(), indent=2)}\n")

# 3. Query
print("3. Querying RAG system...")
query_data = {
    "question": "Quels sont les trois types de machine learning ?",
    "n_results": 3,
    "min_similarity": 0.7,
    "include_sources": True
}
response = requests.post(f"{API_URL}/query", json=query_data)
print(f"Status: {response.status_code}")
result = response.json()
print(f"Answer: {result['answer']}\n")
print(f"Number of sources: {result['num_sources']}\n")

# 4. Stats
print("4. Getting statistics...")
response = requests.get(f"{API_URL}/stats")
print(f"Total chunks: {response.json()['vector_store']['total_chunks']}")
```

Puis ex√©cutez :
```bash
PYTHONPATH=/mnt/e/projetIA .venv/bin/python test_api.py
```

---

## üìù Conseils pour les Questions

Apr√®s avoir upload√© vos documents, testez diff√©rents types de questions :

1. **Questions factuelles** (r√©ponse directe dans le texte)
   - Demandez des d√©finitions, listes ou faits sp√©cifiques

2. **Questions de compr√©hension**
   - Demandez des comparaisons ou explications

3. **Questions de synth√®se**
   - Demandez des r√©sum√©s ou des vues d'ensemble

---

## üêõ D√©pannage

### L'API ne d√©marre pas

**Probl√®me** : `ModuleNotFoundError`
```bash
# Solution : V√©rifier le PYTHONPATH
export PYTHONPATH=/mnt/e/projetIA
```

**Probl√®me** : `Error loading LLM client`
```bash
# Solution : V√©rifier votre cl√© API dans .env
cat .env | grep MISTRAL_API_KEY
```

### Le Frontend ne se connecte pas √† l'API

**Probl√®me** : "‚ùå API Offline" dans Streamlit

**Solutions** :
1. V√©rifiez que l'API est bien lanc√©e sur le port 8000
2. Testez avec : `curl http://localhost:8000/api/v1/health`
3. V√©rifiez qu'il n'y a pas de firewall bloquant le port 8000

### Les r√©ponses sont incoh√©rentes

**Solutions** :
1. V√©rifiez dans Statistics que des chunks sont bien stock√©s
2. Augmentez le nombre de sources (n_results) dans les param√®tres
3. Diminuez le seuil de similarit√© minimum

### GPU non d√©tect√©

**Probl√®me** : "CUDA not available"

**Solutions** :
1. V√©rifiez avec : `.venv/bin/python -c "import torch; print(torch.cuda.is_available())"`
2. Si False, le syst√®me utilisera le CPU (plus lent mais fonctionnel)

---

## ‚úÖ Checklist de Test

- [ ] API d√©marre sans erreur
- [ ] Frontend se connecte √† l'API
- [ ] Upload d'un document r√©ussit
- [ ] Chunks sont cr√©√©s et stock√©s
- [ ] Question simple obtient une r√©ponse
- [ ] Sources sont affich√©es avec scores
- [ ] Statistiques affichent les bonnes valeurs
- [ ] Multiple questions gardent l'historique

---

## üéØ Test Rapide (2 minutes)

```bash
# Terminal 1
./start_api.sh

# Terminal 2 (nouveau terminal)
./start_frontend.sh

# Dans le navigateur (http://localhost:8501)
# 1. Upload votre premier document (PDF, DOCX, TXT)
# 2. Posez une question sur le contenu
# 3. V√©rifiez la r√©ponse et les sources
```

Si tout fonctionne, vous √™tes pr√™t √† utiliser le syst√®me ! üéâ
